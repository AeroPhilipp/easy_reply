{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-txxuuqOs6"
      },
      "source": [
        "# Improve embedding with HuggingFace pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niRPdP0nqTIh",
        "outputId": "0f72f612-1009-499a-9c63-45009005495a"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eQzUCtKqOs7"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "13HbexwlqOs8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_30146/1325072119.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n",
            "/home/isabel/.pyenv/versions/3.10.6/envs/movie_recommendation_GPT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#classic\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#models\n",
        "from transformers import AutoTokenizer, TFAutoModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLFchePGqOs9"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt6c0HxyyrJI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>plot_synopsis</th>\n",
              "      <th>gen_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mr. Holland's Opus</td>\n",
              "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
              "      <td>\"Mr. Holland's Opus\" follows the life of a ded...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Scarface</td>\n",
              "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
              "      <td>\"Scarface\" follows Cuban immigrant Tony Montan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Flightplan</td>\n",
              "      <td>Kyle Pratt (Jodie Foster) is a propulsion engi...</td>\n",
              "      <td>After her husband's sudden death, a grieving w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Little Caesar</td>\n",
              "      <td>Small-time Italian-American criminals Caesar E...</td>\n",
              "      <td>\"Little Caesar\" follows the rise and fall of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Savages</td>\n",
              "      <td>The movie begins with a video being shot of me...</td>\n",
              "      <td>Two marijuana entrepreneurs in California are ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0               title  \\\n",
              "0           0  Mr. Holland's Opus   \n",
              "1           1            Scarface   \n",
              "2           5          Flightplan   \n",
              "3           6       Little Caesar   \n",
              "4           7             Savages   \n",
              "\n",
              "                                       plot_synopsis  \\\n",
              "0  Glenn Holland, not a morning person by anyone'...   \n",
              "1  In May 1980, a Cuban man named Tony Montana (A...   \n",
              "2  Kyle Pratt (Jodie Foster) is a propulsion engi...   \n",
              "3  Small-time Italian-American criminals Caesar E...   \n",
              "4  The movie begins with a video being shot of me...   \n",
              "\n",
              "                                         gen_summary  \n",
              "0  \"Mr. Holland's Opus\" follows the life of a ded...  \n",
              "1  \"Scarface\" follows Cuban immigrant Tony Montan...  \n",
              "2  After her husband's sudden death, a grieving w...  \n",
              "3  \"Little Caesar\" follows the rise and fall of a...  \n",
              "4  Two marijuana entrepreneurs in California are ...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/shared_data/raw_data_shared/movie_with_summary.csv')\n",
        "#df = pd.read_csv('~/code/rossnorman11/raw_data/movie_with_summary.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nauIuYxTqOtB"
      },
      "source": [
        "## 4. Using pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux1DfiOWqOtB"
      },
      "source": [
        "### 1. Text embedding with bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m4gU9XHqOtB",
        "outputId": "1979be2c-e665-4803-f8ff-48ebc89c8990"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModel.from_pretrained(model_name, from_pt = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "soxq3DxP4En0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194/194 [==============================] - 262s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-08 14:28:07.459148: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1588224000 exceeds 10% of free system memory.\n"
          ]
        }
      ],
      "source": [
        "summaries = df['geny_summary'].tolist()\n",
        "\n",
        "# Tokenize the text data\n",
        "token_tensor = tokenizer(summaries, padding='max_length', max_length= 500, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "# Create input tensors\n",
        "input_tensor = token_tensor['input_ids']\n",
        "\n",
        "# Generate embeddings\n",
        "prediction = model.predict(input_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Od-0mkqs4P3b"
      },
      "outputs": [],
      "source": [
        "# Process the embeddings as np\n",
        "summary_embeddings = prediction.last_hidden_state[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/shared_data/raw_data_shared/embedding_summary.npy', summary_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLfIGWP84q5-"
      },
      "source": [
        "**Movie similarity with cosinus similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bsJJRjXp4wZ5"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# # Calculate cosine similarity between embeddings\n",
        "# similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# # Example: Get top 10 most similar movies for each movie\n",
        "# num_movies = similarity_matrix.shape[0]\n",
        "# top_n = 1  # Number of similar movies to retrieve\n",
        "\n",
        "# for i in range(num_movies):\n",
        "#     # Sort similarity scores for movie i\n",
        "#     sim_scores = sorted(enumerate(similarity_matrix[i]), key=lambda x: x[1], reverse=True)\n",
        "#     # Exclude movie i itself\n",
        "#     sim_scores = sim_scores[1:]\n",
        "#     # Get indices of top similar movies\n",
        "#     top_indices = [idx for idx, _ in sim_scores[:top_n]]\n",
        "#     # Print movie titles of top similar movies\n",
        "#     print(f\"Top {top_n} similar movies for '{movie_titles[i]}':\")\n",
        "#     for idx in top_indices:\n",
        "#         print(f\"  - {movie_titles[idx]}\")\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aozptTEv6BEK"
      },
      "source": [
        "**Movie recommendation with cosine similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "FgvA7AP-6Fk1",
        "outputId": "92104b06-f5c3-4c04-e2b1-cab766d96bcd"
      },
      "outputs": [],
      "source": [
        "# # Calculate Movie Similarity\n",
        "\n",
        "# similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# # Select User Preferences\n",
        "# user_input = input(\"Enter a movie title you like: \")\n",
        "\n",
        "# # Retrieve Similar Movies\n",
        "# movie_idx = movie_titles.index(user_input)\n",
        "# sim_scores = list(enumerate(similarity_matrix[movie_idx]))\n",
        "# sim_scores_sorted = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# # Filter Recommendations (optional)\n",
        "# top_n = 5  # Number of recommendations to display\n",
        "# recommended_movies = [movie_titles[idx] for idx, _ in sim_scores_sorted[1:top_n+1]]  # Exclude the input movie itself\n",
        "\n",
        "# # Display Recommendations\n",
        "# print(f\"Recommended movies based on '{user_input}':\")\n",
        "# for movie in recommended_movies:\n",
        "#     print(movie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn0qCJV76PBW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
